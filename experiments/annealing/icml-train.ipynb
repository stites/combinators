{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:/cloud/syncthing/git/combinators appended to python path\n",
      "INFO:root:%load_ext autoreload\n",
      "INFO:root:%autoreload 2\n",
      "INFO:root:from IPython.core.debugger import set_trace\n",
      "INFO:root:from IPython.core.display import display, HTML\n",
      "INFO:root:import torch\n",
      "INFO:root:import numpy as np\n",
      "INFO:root:import scipy as sp\n",
      "INFO:root:import matplotlib\n",
      "INFO:root:import matplotlib.pyplot as plt\n",
      "INFO:root:%matplotlib inline\n",
      "INFO:root:import seaborn as sns\n",
      "INFO:root:import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "%run ../startup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From test_annealing_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import math\n",
    "from torch import nn, Tensor, optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import trange\n",
    "from typing import Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "from pytest import mark, fixture\n",
    "\n",
    "import combinators.trace.utils as trace_utils\n",
    "from combinators.trace.utils import RequiresGrad\n",
    "from combinators.tensor.utils import autodevice, kw_autodevice, copy, show\n",
    "from combinators.densities import MultivariateNormal, Tempered, RingGMM, Normal\n",
    "from combinators.densities.kernels import MultivariateNormalKernel, MultivariateNormalLinearKernel, NormalLinearKernel\n",
    "from combinators.nnets import ResMLPJ\n",
    "from combinators.objectives import nvo_rkl, nvo_avo, mb0, mb1, _estimate_mc, eval_nrep\n",
    "from combinators import Forward, Reverse, Propose, Condition, RequiresGrad, Resample\n",
    "from combinators.stochastic import RandomVariable, ImproperRandomVariable\n",
    "from combinators.metrics import effective_sample_size, log_Z_hat\n",
    "from tests.utils import is_smoketest, seed\n",
    "import combinators.debug as debug\n",
    "\n",
    "import experiments.annealing.visualize as V\n",
    "from experiments.annealing.models import mk_model, sample_along, paper_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-APG additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from combinators.utils import load_models, save_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_annealing_experiment code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(writer, ess, lzh, loss_scalar, i, eval_break, targets, forwards, saveable_models, comment):\n",
    "    with torch.no_grad():\n",
    "        # loss\n",
    "        writer.add_scalar('loss', loss_scalar, i)\n",
    "\n",
    "        # ESS\n",
    "        for step, x in zip(range(1,len(ess)+1), ess):\n",
    "            writer.add_scalar(f'ess/step-{step}', x, i)\n",
    "\n",
    "        # logZhat\n",
    "        for step, x in zip(range(1,len(lzh)+1), lzh):\n",
    "            writer.add_scalar(f'log_Z_hat/step-{step}', x, i)\n",
    "\n",
    "        # show samples\n",
    "        if i % eval_break == 0:\n",
    "            samples = sample_along(targets[0], forwards)\n",
    "            fig = V.scatter_along(samples)\n",
    "            writer.add_figure('overview', fig, global_step=i, close=True)\n",
    "\n",
    "            # =================================================================================================================================\n",
    "            # POST-APG additions\n",
    "            # =================================================================================================================================\n",
    "            save_models(saveable_models, filename=comment)\n",
    "            # =================================================================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_runner(is_smoketest, trainer, resample, objective_tpl, device, budget, num_iterations, lr=1e-3, name=\"\"):\n",
    "    debug.seed()\n",
    "    eval_break=50\n",
    "    num_iterations=3 if is_smoketest else num_iterations\n",
    "    # Setup\n",
    "    oname = objective_tpl[0]\n",
    "    objective = objective_tpl[1]\n",
    "\n",
    "    # Models\n",
    "    out = paper_model(**kw_autodevice(device))\n",
    "    num_samples = 5 if is_smoketest else budget // len(out['targets'])\n",
    "    sample_shape=(num_samples,)\n",
    "    comment=f\"icml-annealing-{name}_{oname}-{'r' if resample else '_'}-d{device}-s{num_samples}-i{num_iterations}-lr{lr}\"\n",
    "\n",
    "\n",
    "\n",
    "    targets, forwards, reverses = [[m.to(autodevice()) for m in out[n]] for n in ['targets', 'forwards', 'reverses']]\n",
    "    saveable_models = {f'{k}-{i}': m for k, ms in dict(targets=targets, forwards=forwards, reverses=reverses).items() for i, m in enumerate(ms)}\n",
    "    try:\n",
    "        saveable_models = load_models(saveable_models, comment)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    assert all([len(list(k.parameters())) >  0 for k in [*forwards, *reverses]])\n",
    "\n",
    "    # logging\n",
    "    writer = SummaryWriter(comment=comment)\n",
    "    loss_ct, loss_sum, loss_avgs, loss_all = 0, 0.0, [], []\n",
    "\n",
    "    optimizer = optim.Adam([dict(params=x.parameters()) for x in [*forwards, *reverses]], lr=lr)\n",
    "\n",
    "    with trange(num_iterations) as bar:\n",
    "        for i in bar:\n",
    "\n",
    "            lvss, loss = trainer(i, targets, forwards, reverses, sample_shape, resample, objective)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # REPORTING\n",
    "            # ---------------------------------------\n",
    "            with torch.no_grad():\n",
    "                lvs = torch.stack(lvss, dim=0)\n",
    "                lws = torch.cumsum(lvs, dim=0)\n",
    "                ess = effective_sample_size(lvs, sample_dims=-1)\n",
    "                lzh = log_Z_hat(lws, sample_dims=-1)\n",
    "\n",
    "                loss_scalar = loss.detach().cpu().mean().item()\n",
    "\n",
    "                report(writer, ess, lzh, loss_scalar, i, eval_break, targets, forwards, saveable_models, comment=comment)\n",
    "\n",
    "                loss_ct += 1\n",
    "                loss_sum += loss_scalar\n",
    "                # Update progress bar\n",
    "                if i % 10 == 0:\n",
    "                    loss_avg = loss_sum / loss_ct\n",
    "                    loss_template = 'loss={: .4f}'.format(loss_avg)\n",
    "                    logZh_template = 'logZhat[-1]={: .4f}'.format(lzh[-1].cpu().item())\n",
    "                    ess_template = 'ess[-1]={: .4f}'.format(ess[-1].cpu().item())\n",
    "                    loss_ct, loss_sum  = 0, 0.0\n",
    "                    bar.set_postfix_str(\"; \".join([loss_template, ess_template, logZh_template]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nvi_eager_resample(i, targets, forwards, reverses, sample_shape, resample, objective):\n",
    "    q0 = targets[0]\n",
    "    p_prv_tr, _, _ = q0(sample_shape=sample_shape)\n",
    "\n",
    "    loss = torch.zeros(1, **kw_autodevice())\n",
    "    lw, lvss = torch.zeros(sample_shape, **kw_autodevice()), []\n",
    "\n",
    "    for k, (fwd, rev, q, p) in enumerate(zip(forwards, reverses, targets[:-1], targets[1:])):\n",
    "        q_ext = Forward(fwd, Condition(q, p_prv_tr, requires_grad=RequiresGrad.NO), _step=k)\n",
    "        p_ext = Reverse(p, rev, _step=k)\n",
    "        extend = Propose(target=p_ext, proposal=q_ext, _step=k)\n",
    "        if resample:\n",
    "            extend = Resample(extend)\n",
    "\n",
    "        state = extend(sample_shape=sample_shape, sample_dims=0, _debug=True)\n",
    "        lv = state.weights\n",
    "\n",
    "        p_prv_tr = state.trace\n",
    "\n",
    "        lw += lv\n",
    "        if resample:\n",
    "            ext_prp = state.program\n",
    "            ext_tar = state.program.target\n",
    "        else:\n",
    "            ext_prp = state.proposal\n",
    "            ext_tar = state.target\n",
    "\n",
    "        loss += objective(lw, lv, ext_prp.trace[f'g{k}'], ext_tar.trace[f'g{k+1}'])\n",
    "\n",
    "        lvss.append(lv)\n",
    "\n",
    "    return lvss, loss\n",
    "\n",
    "rkl_obj = ('rkl', nvo_rkl)\n",
    "avo_obj = ('avo', lambda lw, lv, g_k, g_kp1: nvo_avo(lv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5a3130c4e653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mexperiment_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnvi_eager_resample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_smoketest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mobjective_tpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrkl_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nvi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mexperiment_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnvi_eager_resample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_smoketest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective_tpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mavo_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c25a88aab98b>\u001b[0m in \u001b[0;36mexperiment_runner\u001b[0;34m(is_smoketest, trainer, resample, objective_tpl, device, budget, num_iterations, lr, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mloss_scalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlzh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scalar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_break\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforwards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveable_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mloss_ct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "        # loss += nvo_rkl(lw, lv, ext_prg.trace[f'g{k}'], ext_tar.trace[f'g{k+1}'])\n",
    "        # loss += nvo_avo(lv)\n",
    "\n",
    "budget=288\n",
    "num_iterations=20000\n",
    "\n",
    "experiment_runner(trainer=nvi_eager_resample, device=\"cuda\", is_smoketest=False, resample=False, budget=budget, num_iterations=num_iterations,  objective_tpl=rkl_obj, name='nvi', lr=1e-3)\n",
    "experiment_runner(trainer=nvi_eager_resample, device=\"cuda\", is_smoketest=False, resample=False, budget=budget, num_iterations=num_iterations, objective_tpl=avo_obj, name='avo', lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "experiment_runner(trainer=nvi_eager_resample, device=\"cuda\", is_smoketest=False, resample=False, objective_tpl=rkl_obj, name='nvi', lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_model(resample, objective_tpl, device, num_samples=256, lr=1e-3,num_iterations=10000, name=\"\"):\n",
    "    debug.seed()\n",
    "    # Setup\n",
    "    oname = objective_tpl[0]\n",
    "    objective = objective_tpl[1]\n",
    "    comment=f\"icml-annealing{name}_{oname}-{'r' if resample else '_'}-d{device}-s{num_samples}-i{num_iterations}-lr{lr}\"\n",
    "\n",
    "    # Models\n",
    "    out = paper_model(**kw_autodevice(device))\n",
    "    targets, forwards, reverses = [[m.to(autodevice()) for m in out[n]] for n in ['targets', 'forwards', 'reverses']]\n",
    "    saveable_models = {f'{k}-{i}': m for k, ms in dict(targets=targets, forwards=forwards, reverses=reverses).items() for i, m in enumerate(ms)}\n",
    "    saveable_models = load_models(saveable_models, comment)\n",
    "    return targets, forwards, reverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, forwards, reverses = forward_model(device=\"cuda\", resample=False, objective_tpl=rkl_obj, name='nvi', lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample_along(targets[0], forwards)\n",
    "fig = V.scatter_along(samples[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = samples[-1][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_hist(ax, sample, sort=True, bins=20, range=None, weight_cm=False, show=False, **kwargs):\n",
    "    ax.tick_params(bottom=False, top=False, left=False, right=False,\n",
    "                   labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "    x, y = [sample[:,i].detach().cpu().numpy() for i in [0,1]]\n",
    "    mz, x_e, y_e = np.histogram2d(x, y, bins=bins, density=True, range=range)\n",
    "    X, Y = np.meshgrid(x_e, y_e)\n",
    "    if weight_cm:\n",
    "        raise NotImplemented()\n",
    "    elif show:\n",
    "        ax.imshow(mz, **kwargs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, nrows=1)\n",
    "\n",
    "plot_sample_hist(ax1, samples[-2])\n",
    "plot_sample_hist(ax2, samples[-1])\n",
    "fig.show()\n",
    "# bins = 20\n",
    "# sample= samples[-1]\n",
    "# range=None\n",
    "# x, y = [sample[:,i].detach().cpu().numpy() for i in [0,1]]\n",
    "# mz, x_e, y_e = np.histogram2d(x, y, bins=bins, density=True, range=range)\n",
    "# ax1.imshow(mz, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.image import NonUniformImage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, y = [sample[:,i].detach().cpu().numpy() for i in [0,1]]\n",
    "\n",
    "H, xedges, yedges = np.histogram2d(x, y, bins=50, density=True)\n",
    "\n",
    "H = H.T  # Let each row list bins with common y range.\n",
    "\n",
    "fig, ax1 = plt.subplots(ncols=1, nrows=1)\n",
    "\n",
    "X, Y = np.meshgrid(xedges, yedges)\n",
    "\n",
    "ax1.pcolormesh(X, Y, H)\n",
    "\n",
    "# ax1 = fig.add_subplot(133, title='NonUniformImage: interpolated',\n",
    "#         aspect='equal', xlim=xedges[[0, -1]], ylim=yedges[[0, -1]])\n",
    "\n",
    "# im = NonUniformImage(ax, interpolation='bilinear')\n",
    "\n",
    "# xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "\n",
    "# ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "\n",
    "# im.set_data(xcenters, ycenters, H)\n",
    "\n",
    "# ax.images.append(im)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
